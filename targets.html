<!doctype html>
<html lang="en">
	<head>
		<title>targets</title>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=Edge"/>
		<style>
			body {
				font-family: Monospace;
				background-color: #f0f0f0;
				margin: 0px;
				overflow: hidden;
			}
		</style>
		<script>
			// getUserMedia only works over https in Chrome 47+, so we redirect to https. Also notify user if running from file.
			if (window.location.protocol == "file:") {
				alert("You seem to be running this example directly from a file. Note that these examples only work when served from a server or localhost due to canvas cross-domain restrictions.");
			} else if (window.location.hostname !== "localhost" && window.location.protocol !== "http:"){
				window.location.protocol = "http";
			}
		</script>
		<script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-32642923-1']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = 'http://www' + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
	</head>
	<body>

		<script src="./js/Three.js"></script>
		<script src="./js/Stats.js"></script>
		<script src="./js/Detector.js"></script>
		
		<script src="./js/headtrackr.js"></script>
		
		<canvas id="compare" width="320" height="240" style="display:none"></canvas>
		<video id="vid" autoplay loop></video>
			
		<script>
			if ( ! Detector.webgl ) Detector.addGetWebGLMessage();
			
			var videoInput = document.getElementById('vid');
			var canvasInput = document.getElementById('compare');
			
			// 3d model setup
			
			var container, stats;
			var camera, scene, renderer;
			var plane;
			var profondeur = 200;
			
			function init(profondeur) {
				console.log(window.innerWidth , window.innerHeight)

				container = document.createElement( 'div' );
				document.body.appendChild( container );

				scene = new THREE.Scene();
				scene.fog = new THREE.Fog( 0x000000, 1, 5000 );
		
				camera = new THREE.PerspectiveCamera( 23, window.innerWidth / window.innerHeight, 1, 100000 );
				camera.position.z = 6000;
				scene.add( camera );
				
				// Planes
				
				//top wall
				plane1 = new THREE.Mesh( new THREE.PlaneGeometry( 500, profondeur, 5, 15 ), new THREE.MeshBasicMaterial( { color: 0xcccccc, wireframe : true } ) );
				plane1.rotation.x = Math.PI/2;
				plane1.position.y = 250;
				plane1.position.z = 50-profondeur/2;
				scene.add( plane1 );
				
				//left wall
				plane2 = new THREE.Mesh( new THREE.PlaneGeometry( profondeur, 500, 15, 5 ), new THREE.MeshBasicMaterial( { color: 0xcccccc, wireframe : true } ) );
				plane2.rotation.y = Math.PI/2;
				plane2.position.x = -250;
				plane2.position.z = 50-profondeur/2;
				scene.add( plane2 );
				
				//right wall
				plane3 = new THREE.Mesh( new THREE.PlaneGeometry( profondeur, 500, 15, 5 ), new THREE.MeshBasicMaterial( { color: 0xcccccc, wireframe : true	} ) );
				plane3.rotation.y = -Math.PI/2;
				plane3.position.x = 250;
				plane3.position.z = 50-profondeur/2;
				scene.add( plane3 );
				
				//bottom wall
				plane4 = new THREE.Mesh( new THREE.PlaneGeometry( 500, profondeur, 5, 15 ), new THREE.MeshBasicMaterial( { color: 0xcccccc, wireframe : true	} ) );
				plane4.rotation.x = -Math.PI/2;
				plane4.position.y = -250;
				plane4.position.z = 50-profondeur/2;
				scene.add( plane4 );
				
				
				renderer = new THREE.WebGLRenderer({ clearAlpha: 1 });
				renderer.setSize( window.innerWidth, window.innerHeight );

				container.appendChild( renderer.domElement );
				
			}
			
			var stats = new Stats();
			stats.domElement.style.position = 'absolute';
			stats.domElement.style.top = '0px';
			document.body.appendChild( stats.domElement );
			
			function animate() {

				renderer.render(scene, camera);
				stats.update();

				requestAnimationFrame( animate );

			}
			
			init(profondeur);
			const geometry2 = new THREE.PlaneGeometry( 500, 500, 5,15);
			const material2 = new THREE.MeshBasicMaterial({color:"red", opacity: 0,transparent: true,});
			const virtualWindow = new THREE.Mesh( geometry2, material2 );
			virtualWindow.position.z -= 50
			scene.add(virtualWindow);
			animate();
			
			// video styling
			videoInput.style.position = 'absolute';
			videoInput.style.top = '50px';
			videoInput.style.zIndex = '100001';
			videoInput.style.display = 'block';
			
			// set up camera controller
			headtrackr.controllers.three.MyCameraControl(camera,virtualWindow, [0,0,0]);
			
			// Face detection setup
			var htracker = new headtrackr.Tracker({altVideo : {ogv : "./media/capture5.ogv", mp4 : "./media/capture5.mp4"}});
			htracker.init(videoInput, canvasInput);
			htracker.start();
			
			document.addEventListener('headtrackingEvent', function(event) {
				//scene.fog = new THREE.Fog( 0x000000, 1+(event.z*27), 3000+(event.z*27) );
			}, false);
		</script>
	</body>
</html>
